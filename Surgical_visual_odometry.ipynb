{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data\n",
    "import torch.optim as optim\n",
    "\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "import os\n",
    "from utils import tools\n",
    "# from utils import se3qua\n",
    "\n",
    "import FlowNetC\n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "import flowlib\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import csv\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset:\n",
    "    \n",
    "    def __init__(self, base_dir, sequence):  # base_dir and sequence are directories\n",
    "        self.base_dir = base_dir\n",
    "        self.sequence = sequence\n",
    "        self.base_path_img = self.base_dir + self.sequence + '/cam0/data/'\n",
    "        \n",
    "        \n",
    "        self.data_files = os.listdir(self.base_dir + self.sequence + '/cam0/data/')\n",
    "        self.data_files.sort()\n",
    "        \n",
    "        ## relative camera pose\n",
    "        self.trajectory_relative = self.read_R6TrajFile('/vicon0/sampled_relative_R6.csv')\n",
    "        \n",
    "        ## abosolute camera pose (global)\n",
    "        self.trajectory_abs = self.readTrajectoryFile('/vicon0/sampled.csv')\n",
    "        \n",
    "        ## imu\n",
    "        self.imu = self.readIMU_File('/imu0/data.csv')\n",
    "        \n",
    "        self.imu_seq_len = 5\n",
    "    \n",
    "    def readTrajectoryFile(self, path):\n",
    "        traj = []\n",
    "        with open(self.base_dir + self.sequence + path) as csvfile:\n",
    "            spamreader = csv.reader(csvfile, delimiter=',', quotechar='|')\n",
    "            for row in spamreader:\n",
    "                parsed = [float(row[1]), float(row[2]), float(row[3]), \n",
    "                          float(row[4]), float(row[5]), float(row[6]), float(row[7])]\n",
    "                traj.append(parsed)\n",
    "                \n",
    "        return np.array(traj)\n",
    "    \n",
    "    def read_R6TrajFile(self, path):\n",
    "        traj = []\n",
    "        with open(self.base_dir + self.sequence + path) as csvfile:\n",
    "            spamreader = csv.reader(csvfile, delimiter=',', quotechar='|')\n",
    "            for row in spamreader:\n",
    "                parsed = [float(row[1]), float(row[2]), float(row[3]), \n",
    "                          float(row[4]), float(row[5]), float(row[6])]\n",
    "                traj.append(parsed)\n",
    "                \n",
    "        return np.array(traj)\n",
    "    \n",
    "    def readIMU_File(self, path):\n",
    "        imu = []\n",
    "        count = 0\n",
    "        with open(self.base_dir + self.sequence + path) as csvfile:\n",
    "            spamreader = csv.reader(csvfile, delimiter=',', quotechar='|')\n",
    "            for row in spamreader:\n",
    "                if count == 0:\n",
    "                    count += 1\n",
    "                    continue\n",
    "                parsed = [float(row[1]), float(row[2]), float(row[3]), \n",
    "                          float(row[4]), float(row[5]), float(row[6])]\n",
    "                imu.append(parsed)\n",
    "                \n",
    "        return np.array(imu)\n",
    "    \n",
    "    def getTrajectoryAbs(self, idx):\n",
    "        return self.trajectory_abs[idx]\n",
    "    \n",
    "    def getTrajectoryAbsAll(self):\n",
    "        return self.trajectory_abs\n",
    "    \n",
    "    def getIMU(self):\n",
    "        return self.imu\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.trajectory_relative)\n",
    "    \n",
    "    def load_img_bat(self, idx, batch):\n",
    "        batch_x = []\n",
    "        batch_imu = []\n",
    "        for i in range(batch):\n",
    "            x_data_np_1 = np.array(Image.open(self.base_path_img + self.data_files[idx + i]))\n",
    "            x_data_np_2 = np.array(Image.open(self.base_path_img + self.data_files[idx+1 + i]))\n",
    "\n",
    "            ## 3 channels\n",
    "            x_data_np_1 = np.array([x_data_np_1, x_data_np_1, x_data_np_1])\n",
    "            x_data_np_2 = np.array([x_data_np_2, x_data_np_2, x_data_np_2])\n",
    "\n",
    "            X = np.array([x_data_np_1, x_data_np_2])\n",
    "            batch_x.append(X)\n",
    "\n",
    "            tmp = np.array(self.imu[idx-self.imu_seq_len+1 + i:idx+1 + i])\n",
    "            batch_imu.append(tmp)\n",
    "            \n",
    "        \n",
    "        batch_x = np.array(batch_x)\n",
    "        batch_imu = np.array(batch_imu)\n",
    "        \n",
    "        X = Variable(torch.from_numpy(batch_x).type(torch.FloatTensor).cuda())    \n",
    "        X2 = Variable(torch.from_numpy(batch_imu).type(torch.FloatTensor).cuda())    \n",
    "        \n",
    "        ## F2F gt\n",
    "        Y = Variable(torch.from_numpy(self.trajectory_relative[idx+1:idx+1+batch]).type(torch.FloatTensor).cuda())\n",
    "        \n",
    "        ## global pose gt\n",
    "        Y2 = Variable(torch.from_numpy(self.trajectory_abs[idx+1:idx+1+batch]).type(torch.FloatTensor).cuda())\n",
    "        \n",
    "        return X, X2, Y, Y2   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vinet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Vinet, self).__init__()\n",
    "        self.rnn = nn.LSTM(\n",
    "            input_size=49165,#49152,#24576, \n",
    "            hidden_size=1024,#64, \n",
    "            num_layers=2,\n",
    "            batch_first=True)\n",
    "        self.rnn.cuda()\n",
    "        \n",
    "        self.rnnIMU = nn.LSTM(\n",
    "            input_size=6, \n",
    "            hidden_size=6,\n",
    "            num_layers=2,\n",
    "            batch_first=True)\n",
    "        self.rnnIMU.cuda()\n",
    "        \n",
    "        self.linear1 = nn.Linear(1024, 128)\n",
    "        self.linear2 = nn.Linear(128, 6)\n",
    "        #self.linear3 = nn.Linear(128, 6)\n",
    "        self.linear1.cuda()\n",
    "        self.linear2.cuda()\n",
    "        #self.linear3.cuda()\n",
    "        \n",
    "        \n",
    "        \n",
    "        checkpoint = None\n",
    "        checkpoint_pytorch = 'FlowNet2-C_checkpoint.pth.tar'\n",
    "        #checkpoint_pytorch = '/notebooks/data/model/FlowNet2-SD_checkpoint.pth.tar'\n",
    "        if os.path.isfile(checkpoint_pytorch):\n",
    "            print(f'found the checkpoint file')\n",
    "            checkpoint = torch.load(checkpoint_pytorch,\\\n",
    "                                map_location=lambda storage, loc: storage.cuda(0))\n",
    "            best_err = checkpoint['best_EPE']\n",
    "        else:\n",
    "            print('No checkpoint')\n",
    "\n",
    "        \n",
    "        self.flownet_c = FlowNetC.FlowNetC(batchNorm=False)\n",
    "        self.flownet_c.load_state_dict(checkpoint['state_dict'])\n",
    "        self.flownet_c.cuda()\n",
    "\n",
    "    def forward(self, image, imu, xyzQ):\n",
    "        batch_size, timesteps, C, H, W = image.size()\n",
    "        \n",
    "        ## Input1: Feed image pairs to FlownetC\n",
    "        c_in = image.view(batch_size, timesteps * C, H, W)\n",
    "        c_out = self.flownet_c(c_in)\n",
    "        #print('c_out', c_out.shape)\n",
    "        \n",
    "        ## Input2: Feed IMU records to LSTM\n",
    "        imu_out, (imu_n, imu_c) = self.rnnIMU(imu)\n",
    "        imu_out = imu_out[:, -1, :]\n",
    "        #print('imu_out', imu_out.shape)\n",
    "        imu_out = imu_out.unsqueeze(1)\n",
    "        #print('imu_out', imu_out.shape)\n",
    "        \n",
    "        \n",
    "        ## Combine the output of input1 and 2 and feed it to LSTM\n",
    "        #r_in = c_out.view(batch_size, timesteps, -1)\n",
    "        r_in = c_out.view(batch_size, 1, -1)\n",
    "        #print('r_in', r_in.shape)\n",
    "        \n",
    "\n",
    "        cat_out = torch.cat((r_in, imu_out), 2)#1 1 49158\n",
    "        cat_out = torch.cat((cat_out, xyzQ), 2)#1 1 49165\n",
    "        \n",
    "        r_out, (h_n, h_c) = self.rnn(cat_out)\n",
    "        l_out1 = self.linear1(r_out[:,-1,:])\n",
    "        l_out2 = self.linear2(l_out1)\n",
    "        #l_out3 = self.linear3(l_out2)\n",
    "\n",
    "        return l_out2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found the checkpoint file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/projectx/Documents/GitHub repos/VINET_modification/FlowNetC.py:67: UserWarning: nn.init.uniform is now deprecated in favor of nn.init.uniform_.\n",
      "  init.uniform(m.bias)\n",
      "/home/projectx/Documents/GitHub repos/VINET_modification/FlowNetC.py:68: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "  init.xavier_uniform(m.weight)\n"
     ]
    }
   ],
   "source": [
    "model = Vinet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
